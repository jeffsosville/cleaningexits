name: Daily Business Listings Automation

on:
  schedule:
    - cron: '0 2 * * *'   # 2 AM UTC
  workflow_dispatch:

jobs:
  scrape-and-update:
    runs-on: self-hosted   # your Mac runner
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show runner info (debug)
        run: |
          echo "Host info:"
          uname -a
          sw_vers || true
          which python3 || true
          python3 -V || true

      - name: Create venv + install deps (no root, no cache)
        env:
          PIP_NO_CACHE_DIR: "1"
        run: |
          python3 -m venv .venv
          source .venv/bin/activate
          python -m pip install --upgrade pip
          # if you keep requirements.txt in the repo, great:
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            # fallback: install explicitly
            pip install curl-cffi==0.7.3 supabase==2.8.1 colorama==0.4.6 python-dotenv==1.0.1 requests
          fi

      - name: Run daily scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          MAX_PAGES: "500"
          WORKERS: "5"
        run: |
          source .venv/bin/activate
          python daily_scraper.py
