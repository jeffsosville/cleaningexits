name: Daily Business Listings Automation

on:
schedule:
- cron: '0 2 * * *'
workflow_dispatch:

jobs:
scrape-and-update:
runs-on: [self-hosted, macOS]

env:
  # point the toolcache/temp to places your user can write
  RUNNER_TOOL_CACHE: ${{ github.workspace }}/.cache/tools
  AGENT_TOOLSDIRECTORY: ${{ github.workspace }}/.cache/tools
  RUNNER_TEMP: ${{ github.workspace }}/.cache/temp

steps:
  - uses: actions/checkout@v4

  - name: Prepare tool cache & temp
    run: |
      mkdir -p "$RUNNER_TOOL_CACHE" "$RUNNER_TEMP"
      echo "Tool cache: $RUNNER_TOOL_CACHE"
      echo "Temp: $RUNNER_TEMP"

  - name: Set up Python
    uses: actions/setup-python@v5
    with:
      python-version: '3.11'
      architecture: 'arm64'
      cache: 'pip'

  - name: Install dependencies
    run: |
      python -m pip install --upgrade pip
      pip install --no-cache-dir --upgrade \
        requests supabase==2.8.1 colorama==0.4.6 python-dotenv==1.0.1
      pip install --no-cache-dir --no-binary :all: curl-cffi

  - name: Run daily scraper
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      MAX_P
