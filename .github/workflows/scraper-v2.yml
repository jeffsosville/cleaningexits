name: Daily Business Listings Automation

on:
  schedule:
    - cron: '0 2 * * *'   # Run daily 2 AM UTC
  workflow_dispatch:

jobs:
  scrape-and-update:
    runs-on: [self-hosted, macOS]   # ← use your self-hosted runner

    env:                            # ← add this block
      RUNNER_TOOL_CACHE: ${{ github.workspace }}/.cache/tools
      RUNNER_TEMP: ${{ github.workspace }}/.cache/temp

    steps:
      - uses: actions/checkout@v4

      - name: Prepare tool cache & temp   # ← add this step before setup-python
        run: |
          mkdir -p "$RUNNER_TOOL_CACHE" "$RUNNER_TEMP"
          echo "Tool cache: $RUNNER_TOOL_CACHE"
          echo "Temp: $RUNNER_TEMP"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir --upgrade requests curl-cffi==0.7.3 supabase==2.8.1 colorama==0.4.6 python-dotenv==1.0.1

      - name: Run daily scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          MAX_PAGES: "500"
          WORKERS: "10"
        run: python daily_scraper.py
