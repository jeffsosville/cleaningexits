name: Daily Business Listings Automation

on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch: # Manual trigger
    inputs:
      max_pages:
        description: 'Maximum pages to scrape'
        required: false
        default: '500'
        type: string
      workers:
        description: 'Number of worker threads'
        required: false
        default: '5'
        type: string

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Force full checkout
      
    - name: Debug repository state
      run: |
        echo "=== Repository Debug Info ==="
        echo "Current commit: $(git rev-parse HEAD)"
        echo "Current commit short: $(git rev-parse --short HEAD)"
        echo "Branch: $(git branch --show-current)"
        echo "Last 3 commits:"
        git log --oneline -3
        echo ""
        echo "=== Files in repository ==="
        ls -la
        echo ""
        echo "=== daily_scraper.py file info ==="
        echo "File size: $(wc -l daily_scraper.py) lines"
        echo "Last modified: $(stat -c %y daily_scraper.py)"
        echo ""
        echo "=== First 15 lines of daily_scraper.py ==="
        head -n 15 daily_scraper.py
        echo ""
        echo "=== Checking for curl_cffi imports ==="
        if grep -q "curl_cffi" daily_scraper.py; then
          echo "❌ Found curl_cffi imports:"
          grep -n "curl_cffi" daily_scraper.py
        else
          echo "✅ No curl_cffi imports found"
        fi
        echo ""
        echo "=== Checking for requests imports ==="
        if grep -q "import requests" daily_scraper.py; then
          echo "✅ Found standard requests import:"
          grep -n "import requests" daily_scraper.py
        else
          echo "❌ No standard requests import found"
        fi
        echo ""
        echo "=== Workflow file info ==="
        echo "Workflow file size: $(wc -l .github/workflows/*.yml)"
        echo "Checking for curl-cffi in workflow:"
        if grep -q "curl-cffi" .github/workflows/*.yml; then
          echo "❌ Found curl-cffi in workflow"
          grep -n "curl-cffi" .github/workflows/*.yml
        else
          echo "✅ No curl-cffi found in workflow"
        fi
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Debug Python environment
      run: |
        echo "=== Python Environment ==="
        python --version
        echo "Python executable: $(which python)"
        echo ""
        
    - name: Install Python dependencies
      run: |
        echo "=== Installing Dependencies ==="
        python -m pip install --upgrade pip
        pip install supabase==2.8.1 colorama==0.4.6 python-dotenv==1.0.1 requests
        echo ""
        echo "=== Installed packages ==="
        pip list | grep -E "(supabase|colorama|requests|python-dotenv)"
        
    - name: Verify environment variables
      run: |
        echo "=== Environment Variables Check ==="
        if [ -z "$SUPABASE_URL" ]; then
          echo "❌ SUPABASE_URL is not set"
          exit 1
        else
          echo "✅ SUPABASE_URL is set (length: ${#SUPABASE_URL})"
        fi
        if [ -z "$SUPABASE_KEY" ]; then
          echo "❌ SUPABASE_KEY is not set"  
          exit 1
        else
          echo "✅ SUPABASE_KEY is set (length: ${#SUPABASE_KEY})"
        fi
        echo "MAX_PAGES: $MAX_PAGES"
        echo "WORKERS: $WORKERS"
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        MAX_PAGES: ${{ github.event.inputs.max_pages || '500' }}
        WORKERS: ${{ github.event.inputs.workers || '5' }}
        
    - name: Pre-run script validation
      run: |
        echo "=== Script Validation ==="
        echo "Checking Python syntax:"
        python -m py_compile daily_scraper.py
        if [ $? -eq 0 ]; then
          echo "✅ Python syntax is valid"
        else
          echo "❌ Python syntax error found"
          exit 1
        fi
        echo ""
        echo "=== Import Test ==="
        python -c "
import sys
try:
    import requests
    print('✅ requests import successful')
    print(f'requests version: {requests.__version__}')
except ImportError as e:
    print(f'❌ requests import failed: {e}')
    sys.exit(1)
    
try:
    from supabase import create_client
    print('✅ supabase import successful')  
except ImportError as e:
    print(f'❌ supabase import failed: {e}')
    sys.exit(1)
"
        
    - name: Run daily scraper
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        MAX_PAGES: ${{ github.event.inputs.max_pages || '500' }}
        WORKERS: ${{ github.event.inputs.workers || '5' }}
      run: |
        echo "=== Starting Scraper ==="
        echo "Using MAX_PAGES=$MAX_PAGES, WORKERS=$WORKERS"
        echo "Current directory: $(pwd)"
        echo "Running at: $(date)"
        echo ""
        python daily_scraper.py
        
    - name: Post-run analysis
      if: always()
      run: |
        echo "=== Post-Run Analysis ==="
        echo "Scraper finished at: $(date)"
        if [ -f "scraper.log" ]; then
          echo "Log file size: $(wc -l scraper.log)"
          echo ""
          echo "=== Last 20 lines of log ==="
          tail -n 20 scraper.log
        else
          echo "No scraper.log file found"
        fi
        echo ""
        echo "=== JSON files created ==="
        ls -la *.json 2>/dev/null || echo "No JSON files found"
        
    - name: Upload logs and artifacts
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: scraper-logs-and-data
        path: |
          scraper.log
          *.json
        retention-days: 7
        
    - name: Final status report
      if: always()
      run: |
        echo "=== Final Status Report ==="
        if [ "${{ job.status }}" = "success" ]; then
          echo "✅ Job completed successfully"
        else
          echo "❌ Job failed - check logs above"
          echo "Job URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        fi
