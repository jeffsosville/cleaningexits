name: Daily Business Listings Automation

on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC (fixed: was missing last *)
  workflow_dispatch: # Manual trigger
    inputs:
      max_pages:
        description: 'Maximum pages to scrape'
        required: false
        default: '500'
        type: string
      workers:
        description: 'Number of worker threads'
        required: false
        default: '5'
        type: string

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install supabase==2.8.1 colorama==0.4.6 python-dotenv==1.0.1 requests
        
    - name: Verify environment variables
      run: |
        echo "Checking required environment variables..."
        if [ -z "$SUPABASE_URL" ]; then
          echo "SUPABASE_URL is not set"
          exit 1
        fi
        if [ -z "$SUPABASE_KEY" ]; then
          echo "SUPABASE_KEY is not set"
          exit 1
        fi
        echo "Environment variables are set"
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        
    - name: Run daily scraper
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        MAX_PAGES: ${{ github.event.inputs.max_pages || '500' }}
        WORKERS: ${{ github.event.inputs.workers || '5' }}
      run: |
        echo "Starting scraper with MAX_PAGES=$MAX_PAGES, WORKERS=$WORKERS"
        python daily_scraper.py
        
    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: scraper-logs
        path: |
          scraper.log
          *.json
        retention-days: 7
        
    - name: Notify on failure
      if: failure()
      run: |
        echo "Scraper failed! Check the logs in the artifacts."
        echo "Job URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
